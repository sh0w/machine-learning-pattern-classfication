{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contains Neural Network and IID Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate Baseline Score!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "#just for testing:\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading dataframe\n",
    "df = pd.read_csv(\"dataset/phase_3_TRAIN_7d499bff69ca69b6_6372c3e_MLPC2021_generic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop target value, student annotations and string ID from input features:\n",
    "X = df.drop(columns=['quadrant','mean_A','mean_V','id','score_mode','score_key_strength'])\n",
    "\n",
    "# we want to predict the quadrant:\n",
    "y = df['quadrant'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Pianist</th>\n",
       "      <th>Piece_id</th>\n",
       "      <th>Snippet_number</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GG-01-000</td>\n",
       "      <td>GG</td>\n",
       "      <td>01</td>\n",
       "      <td>000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GG-01-001</td>\n",
       "      <td>GG</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GG-01-002</td>\n",
       "      <td>GG</td>\n",
       "      <td>01</td>\n",
       "      <td>002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GG-01-003</td>\n",
       "      <td>GG</td>\n",
       "      <td>01</td>\n",
       "      <td>003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GG-01-004</td>\n",
       "      <td>GG</td>\n",
       "      <td>01</td>\n",
       "      <td>004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id Pianist Piece_id Snippet_number  class\n",
       "0  GG-01-000      GG       01            000      1\n",
       "1  GG-01-001      GG       01            001      1\n",
       "2  GG-01-002      GG       01            002      1\n",
       "3  GG-01-003      GG       01            003      1\n",
       "4  GG-01-004      GG       01            004      1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#splitting by pianist and piecw!\n",
    "\n",
    "#create tags_dataframe:\n",
    "X_tags=pd.DataFrame()\n",
    "X_tags['id']=df['id']\n",
    "\n",
    "\n",
    "#extract piece_id and pianist to later allow by piece/pianist/both cross validation\n",
    "def extractPianist(x):\n",
    "    return x[0:2]\n",
    "def extract_piece_id(x):\n",
    "    return x[3:5]\n",
    "def extract_snippet_number(x):\n",
    "    return x[6:9]\n",
    "\n",
    "X_tags['Pianist']=X_tags['id'].apply(extractPianist)\n",
    "X_tags['Piece_id']=X_tags['id'].apply(extract_piece_id)\n",
    "X_tags['Snippet_number']=X_tags['id'].apply(extract_snippet_number)\n",
    "X_tags['class']=df['quadrant']\n",
    "\n",
    "X_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get list of pianists and pieces!\n",
    "pianist_list=list(set(X_tags['Pianist']))\n",
    "piece_list=list(set(X_tags['Piece_id']))\n",
    "len(piece_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get distribution of classes per pianist\n",
    "pianist_dist_list=[]\n",
    "pianist_dist_list_perecent=[]\n",
    "for pianist in pianist_list:  \n",
    "    mylist=[]\n",
    "    for i in range(4):\n",
    "        mylist.append(len(X_tags.loc[(X_tags['Pianist'] == pianist) & (X_tags['class']==i+1)]))\n",
    "    pianist_dist_list.append(mylist)\n",
    "    mylist=[element/sum(mylist) for element in mylist]\n",
    "    pianist_dist_list_perecent.append(mylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[70, 46, 294, 72],\n",
       " [73, 48, 210, 95],\n",
       " [95, 62, 148, 65],\n",
       " [71, 58, 183, 70],\n",
       " [70, 28, 280, 83],\n",
       " [94, 32, 265, 95]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pianist_dist_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of classes per pianist seems to be fairly uniform accross all pianist: ->reandom cv_split!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose random pianists\n",
    "pianist_cv=[]\n",
    "number_folds=3\n",
    "\n",
    "#initialize pianists_cv:\n",
    "for i in range(number_folds):\n",
    "    pianist_cv.append([])\n",
    "    \n",
    "#assign pianists to folds randomly\n",
    "cp_pianist_list=pianist_list.copy()\n",
    "for i in range(len(cp_pianist_list)):\n",
    "    choosen_pianist=cp_pianist_list[np.random.randint(len(cp_pianist_list), size=1)[0]]\n",
    "    cp_pianist_list.remove(choosen_pianist)\n",
    "    pianist_cv[len(cp_pianist_list)%number_folds].append(choosen_pianist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['GG', 'FG'], ['RT', 'AS'], ['SR', 'AH']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pianist_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get distribution of classes per piece\n",
    "piece_dist_list=[]\n",
    "piece_dist_list_perecent=[]\n",
    "for piece in piece_list:  \n",
    "    mylist=[]\n",
    "    for i in range(4):\n",
    "        mylist.append(len(X_tags.loc[(X_tags['Piece_id'] == piece) & (X_tags['class']==i+1)]))\n",
    "    piece_dist_list.append(mylist)\n",
    "    mylist=[element/sum(mylist) for element in mylist]\n",
    "    piece_dist_list_perecent.append(mylist)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#piece_dist_list \n",
    "# shows that a lot of pieces are only labled as one emotion! To ensure that all 4 emotions a present\n",
    "# in the test set we can not do a completly random split! IDEA: Create 4 Subesets such that in each subset the majority class of \n",
    "# every piece is the same and then assign sumples from each subset randomly and uiformly to the train test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create 4 subsets:\n",
    "piece_subsets=[]\n",
    "\n",
    "#initialize piece_cv:\n",
    "for i in range(4):\n",
    "    piece_subsets.append([])\n",
    "piece_list_cp=copy.deepcopy(piece_list)\n",
    "for p,piece in enumerate(piece_list):\n",
    "    done=False\n",
    "    for i in range(4):\n",
    "        if not done:\n",
    "            #print(piece_dist_list[p][i])\n",
    "            #print(max(piece_dist_list[p]))\n",
    "            if piece_dist_list[p][i]==max(piece_dist_list[p][:]):\n",
    "                piece_subsets[i].append(piece_list[p])\n",
    "                piece_list_cp.remove\n",
    "                done=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just double checking!\n",
    "np.shape(piece_subsets)\n",
    "piece_subsets\n",
    "mysum=0\n",
    "for i in range(4):\n",
    "    mysum+=len(piece_subsets[i])\n",
    "mysum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chose random pieces using above subset technique:\n",
    "piece_cv=[]\n",
    "number_folds=5\n",
    "#initialize piece_cv:\n",
    "for i in range(number_folds):\n",
    "    piece_cv.append([])\n",
    "    \n",
    "cp_pi_subs = copy.deepcopy(piece_subsets)\n",
    "#assign pieces to folds randomly\n",
    "for i in range(4):\n",
    "    fold=0\n",
    "    for p in range(len(piece_subsets[i])):\n",
    "        chos_piece=cp_pi_subs[i][np.random.randint(len(cp_pi_subs[i]), size=1)[0]]\n",
    "        cp_pi_subs[i].remove(chos_piece)\n",
    "        piece_cv[fold].append(chos_piece)\n",
    "        if fold>=number_folds-1:\n",
    "            fold=0\n",
    "        else:\n",
    "            fold+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['27', '41', '39', '04', '15', '35', '16', '46', '45'],\n",
       " ['37', '29', '11', '47', '08', '02', '34'],\n",
       " ['30', '21', '20', '32', '28', '25', '26'],\n",
       " ['05', '18', '03', '12', '24', '01', '22'],\n",
       " ['09', '14', '31', '36', '19', '38']]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "piece_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just double checking!\n",
    "np.shape(piece_cv)\n",
    "piece_subsets\n",
    "mysum=0\n",
    "for i in range(len(piece_cv)):\n",
    "    mysum+=len(piece_cv[i])\n",
    "mysum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  mask=np.where((X_tags['Pianist'] == pianist_cv[f][i]))[0].index.values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 370  371  372 ... 2604 2605 2606]\n",
      "[   0    1    2 ... 2604 2605 2606]\n",
      "[   0    1    2 ... 2604 2605 2606]\n",
      "[   0    1    2 ... 2604 2605 2606]\n",
      "[   0    1    2 ... 2604 2605 2606]\n",
      "[   0    1    2 ... 2604 2605 2606]\n",
      "[   0    1    2 ... 2604 2605 2606]\n",
      "[   0    1    2 ... 2604 2605 2606]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfor i in range(nFolds):\\n    trainIndices = myDf[ myDf['cvLabel']!=i ].index.values.astype(int)\\n    testIndices =  myDf[ myDf['cvLabel']==i ].index.values.astype(int)\\n    myCViterator.append( (trainIndices, testIndices) )\\nvetrical_mask=[[2,3,4],[3,4,54]]\\n\""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating masks for gridsearch cv:\n",
    "\n",
    "#create vertical splits:\n",
    "myCViterator = []\n",
    "for f,fold in enumerate(pianist_cv):\n",
    "    vetrical_mask_train=np.zeros(0).astype(int)\n",
    "    vetrical_mask_test=np.zeros(0).astype(int)\n",
    "    for i in range(len(fold)):\n",
    "        mask= X_tags[X_tags['Pianist']!=pianist_cv[f][i]].index.values.astype(int)\n",
    "        vetrical_mask_train=np.concatenate((vetrical_mask_train,mask), axis=0)\n",
    "        \n",
    "        mask= X_tags[X_tags['Pianist']==pianist_cv[f][i]].index.values.astype(int)\n",
    "        vetrical_mask_test=np.concatenate((vetrical_mask_test,mask), axis=0)\n",
    "    #print(vetrical_mask_test)\n",
    "    print(vetrical_mask_train)\n",
    "    trainIndices=vetrical_mask_train\n",
    "    testIndices=vetrical_mask_test\n",
    "    myCViterator.append((trainIndices, testIndices))\n",
    "\n",
    "#and create horizontal splits:\n",
    "for f,fold in enumerate(piece_cv):\n",
    "    vetrical_mask_train=np.zeros(0).astype(int)\n",
    "    vetrical_mask_test=np.zeros(0).astype(int)\n",
    "    for i in range(len(fold)):\n",
    "        mask= X_tags[X_tags['Piece_id']!=piece_cv[f][i]].index.values.astype(int)\n",
    "        vetrical_mask_train=np.concatenate((vetrical_mask_train,mask), axis=0)\n",
    "        \n",
    "        mask= X_tags[X_tags['Piece_id']==piece_cv[f][i]].index.values.astype(int)\n",
    "        vetrical_mask_test=np.concatenate((vetrical_mask_test,mask), axis=0)\n",
    "    #print(vetrical_mask_test)\n",
    "    print(vetrical_mask_train)\n",
    "    trainIndices=vetrical_mask_train\n",
    "    testIndices=vetrical_mask_test\n",
    "    myCViterator.append((trainIndices, testIndices))\n",
    "\n",
    "myCViterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=[(array([ 370,  371,  372, ..., 2604, 2605, 2606]),\n",
       "                  array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  9...\n",
       "                                     learning_rate_init=0.001, max_fun=15000,\n",
       "                                     max_iter=200, momentum=0.9,\n",
       "                                     n_iter_no_change=10,\n",
       "                                     nesterovs_momentum=True, power_t=0.5,\n",
       "                                     random_state=None, shuffle=True,\n",
       "                                     solver='adam', tol=0.0001,\n",
       "                                     validation_fraction=0.1, verbose=False,\n",
       "                                     warm_start=False),\n",
       "             iid='deprecated', n_jobs=None, param_grid={},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cv = GridSearchCV(MLPClassifier(hidden_layer_sizes=(4,40)), param_grid = {}, cv=myCViterator)\n",
    "gs_cv.fit(pd.DataFrame(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([18.95722851]),\n",
       " 'std_fit_time': array([18.49769549]),\n",
       " 'mean_score_time': array([0.0117979]),\n",
       " 'std_score_time': array([0.0042232]),\n",
       " 'params': [{}],\n",
       " 'split0_test_score': array([0.52816901]),\n",
       " 'split1_test_score': array([0.51612903]),\n",
       " 'split2_test_score': array([0.5524239]),\n",
       " 'split3_test_score': array([0.65987461]),\n",
       " 'split4_test_score': array([0.57491857]),\n",
       " 'split5_test_score': array([0.41386555]),\n",
       " 'split6_test_score': array([0.63326226]),\n",
       " 'split7_test_score': array([0.65609756]),\n",
       " 'mean_test_score': array([0.56684256]),\n",
       " 'std_test_score': array([0.07808296]),\n",
       " 'rank_test_score': array([1])}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cv.cv_results_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (AI)",
   "language": "python",
   "name": "ai"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
